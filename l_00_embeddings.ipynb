{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>What are embeddings?</h3>\n",
    "\n",
    "- Embeddings are numerical representations of concepts converted to number sequences, which make it easy for computers to understand the relationships between those concepts. \n",
    "  Text embeddings measure the relatedness of text strings. \n",
    "  \n",
    "\n",
    "- Embeddings are useful for working with natural language and code, because they can be readily consumed and compared by other machine learning models and algorithms like clustering or search.\n",
    "\n",
    "- Embeddings that are numerically similar are also semantically similar. \n",
    "\n",
    "[Embeddings by OpenAI](https://openai.com/blog/introducing-text-and-code-embeddings?source=post_page-----d5d438bb5766--------------------------------)\n",
    "\n",
    "\n",
    "<h3>Embeddings are commonly used for:</h3>\n",
    "\n",
    "- Search (where results are ranked by relevance to a query string)\n",
    "\n",
    "- Clustering (where text strings are grouped by similarity)\n",
    "\n",
    "- Recommendations (where items with related text strings are recommended)\n",
    "\n",
    "- Anomaly detection (where outliers with little relatedness are identified)\n",
    "\n",
    "- Diversity measurement (where similarity distributions are analyzed)\n",
    "\n",
    "- Classification (where text strings are classified by their most similar label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Cosine similarity algorithm: Deep dive</h3>\n",
    "\n",
    "Cosine similarity is a measure of similarity between two non-zero vectors of an inner product space based on the cosine of the angle between them, resulting in a value between -1 and 1. The value -1 means that the vectors are opposite, 0 represents orthogonal vectors, and value 1 signifies similar vectors.\n",
    "\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "<img src=\"./img/cosine-similarity.png\" width=\"800px\"/>\n",
    "\n",
    "<br>\n",
    "\n",
    "To compute the cosine similarity between vectors A and B, you can use the following formula:\n",
    "<br><br>\n",
    "<img src=\"./img/similarity-formula.png\" width=\"400px\"/>\n",
    "\n",
    "<br>\n",
    "\n",
    "The cosine similarity is often used in text analytics to compare documents and determine if they’re similar and how much. In that case, documents must be represented as a vector, where a unique word is a dimension and the frequency or weight of that unique word in the document represents the value of that specific dimension. After the transformation of documents to vectors is done, comparison using cosine similarity is relatively straightforward — we measure the cosine of the angle between their vectors. If the angle between vectors (documents) is small, then the cosine of the angle is high, and hence, documents are similar. Opposite to that, if the angle between vectors (documents) is large, then the cosine of the angle is low, resulting in opposite documents (not similar). Cosine similarity considers the orientation of the vectors, but it does not take their magnitudes into account. In the previous example, this means that even documents of totally different lengths can be considered similar if they are related to the same topic.\n",
    "\n",
    "> Intuitive interpretation and versatility of the cosine similarity algorithm have found their way into various applications, spanning from text analysis and recommendation systems to complex graph databases. The algorithm's ability to capture the orientation of vectors makes it a robust measure of similarity, especially in high-dimensional spaces.\n",
    "\n",
    "[source](https://memgraph.com/blog/cosine-similarity-python-scikit-learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xandg\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe: No module named spacy\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'spacy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\xandg\\Ambiente de Trabalho\\IMS\\3rd year\\1st Semester\\Capstone Project\\OpenAI\\cp-08-langchain-intro\\l_00_embeddings.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/xandg/Ambiente%20de%20Trabalho/IMS/3rd%20year/1st%20Semester/Capstone%20Project/OpenAI/cp-08-langchain-intro/l_00_embeddings.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mspacy\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/xandg/Ambiente%20de%20Trabalho/IMS/3rd%20year/1st%20Semester/Capstone%20Project/OpenAI/cp-08-langchain-intro/l_00_embeddings.ipynb#W5sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m nlp \u001b[39m=\u001b[39m spacy\u001b[39m.\u001b[39mload(\u001b[39m\"\u001b[39m\u001b[39men_core_web_md\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/xandg/Ambiente%20de%20Trabalho/IMS/3rd%20year/1st%20Semester/Capstone%20Project/OpenAI/cp-08-langchain-intro/l_00_embeddings.ipynb#W5sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m dog_embedding \u001b[39m=\u001b[39m nlp\u001b[39m.\u001b[39mvocab[\u001b[39m\"\u001b[39m\u001b[39mdog\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mvector\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'spacy'"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "dog_embedding = nlp.vocab[\"dog\"].vector\n",
    "\n",
    "type(dog_embedding)\n",
    "\n",
    "\n",
    "print(dog_embedding.shape)\n",
    "\n",
    "\n",
    "dog_embedding[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_cosine_similarity(u: np.ndarray, v: np.ndarray) -> float:\n",
    "    \"\"\"Compute the cosine similarity between two vectors\"\"\"\n",
    "\n",
    "    return (u @ v) / (np.linalg.norm(u) * np.linalg.norm(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\xandg\\Ambiente de Trabalho\\IMS\\3rd year\\1st Semester\\Capstone Project\\OpenAI\\cp-08-langchain-intro\\l_00_embeddings.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/xandg/Ambiente%20de%20Trabalho/IMS/3rd%20year/1st%20Semester/Capstone%20Project/OpenAI/cp-08-langchain-intro/l_00_embeddings.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpairwise\u001b[39;00m \u001b[39mimport\u001b[39;00m cosine_similarity\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/xandg/Ambiente%20de%20Trabalho/IMS/3rd%20year/1st%20Semester/Capstone%20Project/OpenAI/cp-08-langchain-intro/l_00_embeddings.ipynb#X10sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m nlp \u001b[39m=\u001b[39m spacy\u001b[39m.\u001b[39mload(\u001b[39m\"\u001b[39m\u001b[39men_core_web_md\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/xandg/Ambiente%20de%20Trabalho/IMS/3rd%20year/1st%20Semester/Capstone%20Project/OpenAI/cp-08-langchain-intro/l_00_embeddings.ipynb#X10sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m dog_embedding \u001b[39m=\u001b[39m nlp\u001b[39m.\u001b[39mvocab[\u001b[39m\"\u001b[39m\u001b[39mdog\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mvector\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "dog_embedding = nlp.vocab[\"dog\"].vector\n",
    "cat_embedding = nlp.vocab[\"cat\"].vector\n",
    "apple_embedding = nlp.vocab[\"apple\"].vector\n",
    "tasty_embedding = nlp.vocab[\"tasty\"].vector\n",
    "delicious_embedding = nlp.vocab[\"delicious\"].vector\n",
    "truck_embedding = nlp.vocab[\"truck\"].vector\n",
    "\n",
    "dog_embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosine_similarity(dog, cat)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'cosine_similarity' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\xandg\\Ambiente de Trabalho\\IMS\\3rd year\\1st Semester\\Capstone Project\\OpenAI\\cp-08-langchain-intro\\l_00_embeddings.ipynb Cell 9\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/xandg/Ambiente%20de%20Trabalho/IMS/3rd%20year/1st%20Semester/Capstone%20Project/OpenAI/cp-08-langchain-intro/l_00_embeddings.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mcosine_similarity(dog, cat)\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/xandg/Ambiente%20de%20Trabalho/IMS/3rd%20year/1st%20Semester/Capstone%20Project/OpenAI/cp-08-langchain-intro/l_00_embeddings.ipynb#X11sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(cosine_similarity([dog_embedding], [cat_embedding])[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m],\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/xandg/Ambiente%20de%20Trabalho/IMS/3rd%20year/1st%20Semester/Capstone%20Project/OpenAI/cp-08-langchain-intro/l_00_embeddings.ipynb#X11sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mcosine_similarity(delicious, tasty)\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/xandg/Ambiente%20de%20Trabalho/IMS/3rd%20year/1st%20Semester/Capstone%20Project/OpenAI/cp-08-langchain-intro/l_00_embeddings.ipynb#X11sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mprint\u001b[39m(cosine_similarity([delicious_embedding], [tasty_embedding])[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m],\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cosine_similarity' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"cosine_similarity(dog, cat)\")\n",
    "print(cosine_similarity([dog_embedding], [cat_embedding])[0][0],\"\\n\")\n",
    "\n",
    "print(\"cosine_similarity(delicious, tasty)\")\n",
    "print(cosine_similarity([delicious_embedding], [tasty_embedding])[0][0],\"\\n\")\n",
    "\n",
    "print(\"cosine_similarity(apple, delicious)\")\n",
    "print(cosine_similarity([apple_embedding], [delicious_embedding])[0][0],\"\\n\")\n",
    "\n",
    "print(\"cosine_similarity(dog, apple)\")\n",
    "print(cosine_similarity([dog_embedding], [apple_embedding])[0][0],\"\\n\")\n",
    "\n",
    "print(\"cosine_similarity(truck, delicious)\")\n",
    "print(cosine_similarity([truck_embedding], [delicious_embedding])[0][0],\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Illustrative - to create an intuition about word similarity by using embeddings</h4>\n",
    "\n",
    "<img src=\"./img/2d-embeddings-ex.png\" width=\"800px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./img/cosine-similarity.png\" width=\"800px\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4, 384)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "texts = [\n",
    "         \"The canine barked loudly.\",\n",
    "         \"The dog made a noisy bark.\",\n",
    "         \"He ate a lot of pizza.\",\n",
    "         \"He devoured a large quantity of pizza pie.\",\n",
    "]\n",
    "\n",
    "text_embeddings = model.encode(texts)\n",
    "\n",
    "print(type(text_embeddings))\n",
    "\n",
    "\n",
    "text_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "text_embeddings_dict = dict(zip(texts, list(text_embeddings)))\n",
    "\n",
    "dog_text_1 = \"The canine barked loudly.\"\n",
    "dog_text_2 = \"The dog made a noisy bark.\"\n",
    "pizza_text_1 = \"He ate a lot of pizza.\"\n",
    "pizza_test_2 = \"He devoured a large quantity of pizza pie.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The canine barked loudly.\n",
      "The dog made a noisy bark.\n",
      "Similarity: 0.7768615484237671\n",
      "\n",
      "\n",
      "He ate a lot of pizza.\n",
      "He devoured a large quantity of pizza pie.\n",
      "Similarity: 0.7871338725090027\n",
      "\n",
      "\n",
      "The canine barked loudly.\n",
      "He ate a lot of pizza.\n",
      "Similarity: 0.09128269553184509\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sim1 = cosine_similarity(\n",
    "    [text_embeddings_dict[dog_text_1]],\n",
    "    [text_embeddings_dict[dog_text_2]]\n",
    ")\n",
    "\n",
    "print(f\"\"\"\n",
    "{dog_text_1}\n",
    "{dog_text_2}\n",
    "Similarity: {sim1[0][0]}\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "\n",
    "sim2 = cosine_similarity(\n",
    "    [text_embeddings_dict[pizza_text_1]],\n",
    "    [text_embeddings_dict[pizza_test_2]]\n",
    ")\n",
    "\n",
    "print(f\"\"\"\n",
    "{pizza_text_1}\n",
    "{pizza_test_2}\n",
    "Similarity: {sim2[0][0]}\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "sim3 = cosine_similarity(\n",
    "    [text_embeddings_dict[dog_text_1]],\n",
    "    [text_embeddings_dict[pizza_text_1]]\n",
    ")\n",
    "\n",
    "print(f\"\"\"\n",
    "{dog_text_1}\n",
    "{pizza_text_1}\n",
    "Similarity: {sim3[0][0]}\n",
    "\"\"\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
